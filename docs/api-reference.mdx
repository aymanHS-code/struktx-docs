---
title: "API Reference"
description: "Complete API reference for StruktX interfaces, types, and components"
---

## Core Types

### StruktConfig

Main configuration object for the framework.

```python
class StruktConfig:
    llm: Optional[LLMClientConfig] = None
    classifier: ClassifierConfig
    handlers: HandlersConfig
    memory: Optional[MemoryConfig] = None
    middleware: Optional[list[Callable]] = None
    extras: Optional[ExtrasConfig] = None
```

### InvocationState

Contains the current request state:

```python
class InvocationState:
    text: str                    # User input
    context: dict               # Request context
    metadata: dict              # Additional metadata
```

### QueryClassification

Result of query classification:

```python
class QueryClassification:
    query_type: str             # Handler to route to
    parts: list[str]            # Parsed query parts
    confidence: float           # Classification confidence
```

### HandlerResult

Result from handler processing:

```python
class HandlerResult:
    response: str               # Response text
    status: str                 # Processing status
    metadata: dict              # Additional metadata
```

## Interfaces

### LLMClient

```python
class LLMClient(Protocol):
    def invoke(self, text: str) -> str:
        """Basic text completion"""
        ...
    
    def structured(self, prompt: str, model: BaseModel) -> BaseModel:
        """Structured output with Pydantic model"""
        ...
```

### Classifier

```python
class Classifier(Protocol):
    def classify(self, state: InvocationState) -> QueryClassification:
        """Routes queries to appropriate handlers"""
        ...
```

### Handler

```python
class Handler(Protocol):
    def handle(self, state: InvocationState, parts: list[str]) -> HandlerResult:
        """Processes queries and returns responses"""
        ...
```

### MemoryEngine

```python
class MemoryEngine(Protocol):
    def get(self, key: str) -> list[dict]:
        """Retrieve conversation history"""
        ...
    
    def add(self, key: str, message: dict) -> None:
        """Add message to history"""
        ...
    
    def clear(self, key: str) -> None:
        """Clear conversation history"""
        ...

    # New: scoped semantic retrieval
    def get_scoped(self, query: str, user_id: Optional[str] = None, unit_id: Optional[str] = None, top_k: int = 5) -> list[str]:
        """Retrieve relevant memory strings scoped by user/unit."""
        ...
```

### Middleware

```python
class Middleware(Protocol):
    def before_classify(self, state: InvocationState) -> InvocationState:
        """Called before query classification"""
        ...
    
    def after_classify(self, state: InvocationState) -> InvocationState:
        """Called after query classification"""
        ...
    
    def before_handle(self, state: InvocationState) -> InvocationState:
        """Called before handler execution"""
        ...
    
    def after_handle(self, state: InvocationState) -> InvocationState:
        """Called after handler execution"""
        ...
```

## Configuration Classes

### LLMClientConfig

```python
class LLMClientConfig:
    factory: Union[Callable, str]    # Factory function, class, instance, or import string "module:attr"
    params: Optional[dict] = None    # Additional parameters passed to the factory
```

### ClassifierConfig

```python
class ClassifierConfig:
    factory: Union[Callable, str]    # Factory function or import string
    params: Optional[dict] = None    # Additional parameters
```

### HandlersConfig

```python
class HandlersConfig:
    registry: dict[str, Callable]    # Handler registry
    default_route: str               # Default handler route
    handler_params: Optional[dict] = None  # Per-handler parameters
```

### MiddlewareConfig

```python
class MiddlewareConfig:
    factory: Union[Callable, str]
    params: Optional[dict] = None
```

### MemoryConfig

```python
class MemoryConfig:
    factory: Union[Callable, str]    # Factory function or import string
    params: Optional[dict] = None    # Additional parameters
    use_store: bool = False          # Bind a local KnowledgeStore to the engine
    augment_llm: bool = False        # Automatically inject retrieved memory into LLM prompts
```

### KnowledgeStore

```python
class KnowledgeStore:
    def create_and_add_node(...): ...
    def create_and_add_edge(...): ...
    def add_node(self, node, sync: bool = False): ...
    def add_edge(self, edge, sync: bool = False): ...
    def list_engine_memories_for_scope(self, user_id: str, unit_id: Optional[str], limit: int = 50) -> list[str]: ...
```

### ExtrasConfig

```python
class ExtrasConfig:
    humanlayer: HumanLayerConfig     # Human layer configuration
```

### HumanLayerConfig

```python
class HumanLayerConfig:
    enabled: bool = False            # Whether human layer is enabled
```

## LangChain Helpers

### create_structured_chain

```python
def create_structured_chain(
    llm_client: LLMClient,
    prompt_template: str,
    output_model: Type[BaseModel],
    input_variables: list[str]
) -> StructuredChain:
    """
    Create a structured chain with Pydantic model output.
    
    Args:
        llm_client: LLM client instance
        prompt_template: Prompt template string
        output_model: Pydantic model for structured output
        input_variables: List of input variable names
    
    Returns:
        StructuredChain instance
    """
```

### LangChainLLMClient (adapter)

```python
class LangChainLLMClient:
    def __init__(self, langchain_llm):
        """
        Initialize with a LangChain LLM instance.
        
        Args:
            langchain_llm: LangChain LLM instance (e.g., ChatOpenAI)
        """
    
    def invoke(self, text: str) -> str:
        """Basic text completion"""
    
    def structured(self, prompt: str, model: BaseModel) -> BaseModel:
        """Structured output with Pydantic model"""
```

<Note>
  You can pass LangChain chat models directly via <code>LLMClientConfig(factory="langchain_openai:ChatOpenAI", params={...})</code>. StruktX will adapt them automatically.
</Note>

## Built-in Components

### SimpleKeywordClassifier

```python
class SimpleKeywordClassifier:
    def __init__(self, keywords: Optional[dict[str, list[str]]] = None):
        """
        Initialize with keyword mappings.
        
        Args:
            keywords: Dictionary mapping query types to keyword lists
        """
    
    def classify(self, state: InvocationState) -> QueryClassification:
        """Classify based on keyword matching"""
```

### DefaultLLMClassifier

```python
class DefaultLLMClassifier:
    def __init__(
        self,
        llm: LLMClient,
        prompt_template: str,
        allowed_types: list[str],
        max_parts: int = 4
    ):
        """
        Initialize LLM-powered classifier.
        
        Args:
            llm: LLM client instance
            prompt_template: Classification prompt template
            allowed_types: List of allowed query types
            max_parts: Maximum number of parts to extract
        """
    
    def classify(self, state: InvocationState) -> QueryClassification:
        """Classify using LLM"""
```

### TimeHandler

```python
class TimeHandler:
    def __init__(self, llm: LLMClient):
        """
        Initialize time handler.
        
        Args:
            llm: LLM client instance
        """
    
    def handle(self, state: InvocationState, parts: list[str]) -> HandlerResult:
        """Handle time-related queries"""
```

## Memory Engines

### VectorMemoryEngine

```python
class VectorMemoryEngine:
    def __init__(self, vector_store, embedding_model):
        """
        Initialize vector-based memory.
        
        Args:
            vector_store: Vector store instance
            embedding_model: Embedding model instance
        """
    
    def get(self, key: str) -> list[dict]:
        """Get relevant conversation history"""
    
    def add(self, key: str, message: dict) -> None:
        """Add message to vector store"""
    
    def clear(self, key: str) -> None:
        """Clear conversation history"""
```

### UpstashVectorMemoryEngine

```python
class UpstashVectorMemoryEngine(VectorMemoryEngine):
    def __init__(self, index_url: str, index_token: str, namespace: Optional[str] = None):
        """Adapter for Upstash Vector with node/edge storage and metadata scoping."""
```

## Built-in Middleware

### LoggingMiddleware

```python
class LoggingMiddleware:
    def __init__(self, verbose: bool = False, log_file: Optional[str] = None):
        """
        Initialize logging middleware.
        
        Args:
            verbose: Enable verbose logging
            log_file: Custom log file path
        """
```

### MemoryExtractionMiddleware

```python
class MemoryExtractionMiddleware:
    """Extracts durable facts/preferences from invocations and stores them, preventing duplicates."""
```

### ApprovalMiddleware

```python
class ApprovalMiddleware:
    def __init__(self, rule: Callable):
        """
        Initialize approval middleware.
        
        Args:
            rule: Approval rule function
        """
```

## Error Types

### StruktError

Base exception for StruktX errors.

```python
class StruktError(Exception):
    """Base exception for StruktX errors"""
```

### ConfigurationError

Raised when there's a configuration issue.

```python
class ConfigurationError(StruktError):
    """Raised when there's a configuration issue"""
```

### HandlerError

Raised when a handler encounters an error.

```python
class HandlerError(StruktError):
    """Raised when a handler encounters an error"""
```

## Utility Functions

### create

```python
def create(config: StruktConfig) -> StruktApp:
    """
    Create a StruktX application.
    
    Args:
        config: Application configuration
    
    Returns:
        StruktApp instance
    """
```

### StruktApp memory helpers

```python
class StruktApp:
    def get_memory(self) -> MemoryEngine: ...
    def get_memory_store(self) -> KnowledgeStore: ...
    def add_memory(self, text: str, metadata: Optional[dict] = None) -> None: ...
    def retrieve_memory(self, query: str, top_k: int = 5) -> list[str]: ...
```

### load_factory

```python
def load_factory(factory_spec: Union[Callable, str]) -> Callable:
    """
    Load a factory function from specification.
    
    Args:
        factory_spec: Factory function or import string
    
    Returns:
        Factory function
    """
```

## Type Aliases

```python
# Common type aliases used throughout StruktX
Factory = Union[Callable, str]
MiddlewareFactory = Callable[..., Middleware]
HandlerFactory = Callable[..., Handler]
ClassifierFactory = Callable[..., Classifier]
LLMFactory = Callable[..., LLMClient]
MemoryFactory = Callable[..., MemoryEngine]
```

<Info>
  This API reference covers all the main interfaces and types in StruktX. For more detailed examples and usage patterns, see the Examples and Configuration pages.
</Info>